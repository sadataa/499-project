{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUANWN3rpfC9"
      },
      "source": [
        "# 0. Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "146BB11JpfDA"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "42hJEdo_pfDB"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hbPhYVy_pfDB"
      },
      "outputs": [],
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LwhWZMI0pfDC"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HR-TfDGrpfDC"
      },
      "outputs": [],
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-rs_ipfDE"
      },
      "source": [
        "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "yNT0lnVDLg4h"
      },
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/install/source_windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "K-Cmz2edpfDE",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "if os.name=='nt':\n",
        "    !pip install wget\n",
        "    import wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iA1DIq5OpfDE"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rJjMHbnDs3Tv",
        "outputId": "dbc0af19-df0d-455b-bf45-8ae80f3cce73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "Processing /content/Tensorflow/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: avro-python3 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.10.2)\n",
            "Requirement already satisfied: apache-beam in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.38.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.28)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Requirement already satisfied: lvis in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Requirement already satisfied: tf-models-official>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.25.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.5.2.52)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.16.1)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.6)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: tensorflow-text~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.1)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.5)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.1)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.20.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.44.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (13.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.25.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: orjson<4.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.6.8)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.20.3)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.4.10)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
            "Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.4.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1691106 sha256=919a424a1d35342deea5d0cd4daee6654a4a353e61c4a7054669269a77f51bd1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mj3j0z79/wheels/a9/26/bf/1cb2313ed4855917889b97658bf0a19999e3588e47867bdaee\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "  Attempting uninstall: object-detection\n",
            "    Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "Successfully installed object-detection-0.1\n"
          ]
        }
      ],
      "source": [
        "# Install Tensorflow Object Detection \n",
        "if os.name=='posix':  \n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
        "    \n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": true,
        "id": "NR_EqkFVLg5c",
        "outputId": "f132e710-7100-45ca-f56e-108d24c4b9a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running tests under Python 3.7.13: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-04-23 19:29:43.594723: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0423 19:29:43.849046 140471613556608 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.39s\n",
            "I0423 19:29:44.226448 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.39s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.52s\n",
            "I0423 19:29:44.748143 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.52s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.29s\n",
            "I0423 19:29:45.037528 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.29s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.25s\n",
            "I0423 19:29:45.288105 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.25s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.83s\n",
            "I0423 19:29:47.116713 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.83s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0423 19:29:47.117675 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I0423 19:29:47.141946 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I0423 19:29:47.156988 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0423 19:29:47.172781 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n",
            "I0423 19:29:47.272042 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n",
            "I0423 19:29:47.369514 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n",
            "I0423 19:29:47.472405 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n",
            "I0423 19:29:47.569612 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "I0423 19:29:47.670264 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0423 19:29:47.700392 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0423 19:29:47.899744 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0423 19:29:47.899912 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0423 19:29:47.899992 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0423 19:29:47.902211 140471613556608 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0423 19:29:47.918217 140471613556608 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0423 19:29:47.918347 140471613556608 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0423 19:29:47.980398 140471613556608 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0423 19:29:47.980538 140471613556608 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0423 19:29:48.135952 140471613556608 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0423 19:29:48.136106 140471613556608 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0423 19:29:48.285104 140471613556608 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0423 19:29:48.285276 140471613556608 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0423 19:29:48.530813 140471613556608 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0423 19:29:48.530993 140471613556608 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0423 19:29:48.760293 140471613556608 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0423 19:29:48.760468 140471613556608 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0423 19:29:49.245622 140471613556608 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0423 19:29:49.245806 140471613556608 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I0423 19:29:49.320614 140471613556608 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I0423 19:29:49.350465 140471613556608 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0423 19:29:49.403246 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0423 19:29:49.403389 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0423 19:29:49.403477 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0423 19:29:49.405053 140471613556608 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0423 19:29:49.419955 140471613556608 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0423 19:29:49.420068 140471613556608 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0423 19:29:49.539513 140471613556608 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0423 19:29:49.539639 140471613556608 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0423 19:29:49.762144 140471613556608 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0423 19:29:49.762287 140471613556608 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0423 19:29:50.005471 140471613556608 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0423 19:29:50.005625 140471613556608 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0423 19:29:50.323942 140471613556608 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0423 19:29:50.324133 140471613556608 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0423 19:29:50.638110 140471613556608 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0423 19:29:50.638285 140471613556608 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0423 19:29:51.028431 140471613556608 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0423 19:29:51.028623 140471613556608 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I0423 19:29:51.176935 140471613556608 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I0423 19:29:51.206287 140471613556608 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0423 19:29:51.272804 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0423 19:29:51.272958 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0423 19:29:51.273041 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0423 19:29:51.274651 140471613556608 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0423 19:29:51.290104 140471613556608 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0423 19:29:51.290226 140471613556608 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0423 19:29:51.411029 140471613556608 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0423 19:29:51.411161 140471613556608 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0423 19:29:51.639739 140471613556608 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0423 19:29:51.639904 140471613556608 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0423 19:29:51.866685 140471613556608 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0423 19:29:51.866849 140471613556608 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I0423 19:29:52.184151 140471613556608 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I0423 19:29:52.184333 140471613556608 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I0423 19:29:52.492720 140471613556608 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I0423 19:29:52.492905 140471613556608 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I0423 19:29:52.881161 140471613556608 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I0423 19:29:52.881348 140471613556608 efficientnet_model.py:144] round_filter input=320 output=352\n",
            "I0423 19:29:53.041342 140471613556608 efficientnet_model.py:144] round_filter input=1280 output=1408\n",
            "I0423 19:29:53.071015 140471613556608 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0423 19:29:53.133058 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0423 19:29:53.133208 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0423 19:29:53.133285 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0423 19:29:53.134904 140471613556608 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I0423 19:29:53.153617 140471613556608 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I0423 19:29:53.153727 140471613556608 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0423 19:29:53.475380 140471613556608 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0423 19:29:53.475563 140471613556608 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0423 19:29:53.699625 140471613556608 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0423 19:29:53.699795 140471613556608 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0423 19:29:53.929012 140471613556608 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0423 19:29:53.929186 140471613556608 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I0423 19:29:54.324043 140471613556608 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I0423 19:29:54.324226 140471613556608 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I0423 19:29:54.709288 140471613556608 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I0423 19:29:54.709471 140471613556608 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I0423 19:29:55.180788 140471613556608 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I0423 19:29:55.180980 140471613556608 efficientnet_model.py:144] round_filter input=320 output=384\n",
            "I0423 19:29:55.330769 140471613556608 efficientnet_model.py:144] round_filter input=1280 output=1536\n",
            "I0423 19:29:55.360659 140471613556608 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0423 19:29:55.430034 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0423 19:29:55.430178 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0423 19:29:55.430251 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0423 19:29:55.431918 140471613556608 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0423 19:29:55.448545 140471613556608 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0423 19:29:55.448680 140471613556608 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0423 19:29:55.570951 140471613556608 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0423 19:29:55.571085 140471613556608 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0423 19:29:55.868853 140471613556608 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0423 19:29:55.869001 140471613556608 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I0423 19:29:56.183079 140471613556608 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I0423 19:29:56.183249 140471613556608 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I0423 19:29:56.633200 140471613556608 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I0423 19:29:56.633385 140471613556608 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I0423 19:29:57.097664 140471613556608 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I0423 19:29:57.097849 140471613556608 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I0423 19:29:57.704544 140471613556608 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I0423 19:29:57.704722 140471613556608 efficientnet_model.py:144] round_filter input=320 output=448\n",
            "I0423 19:29:57.857459 140471613556608 efficientnet_model.py:144] round_filter input=1280 output=1792\n",
            "I0423 19:29:57.886506 140471613556608 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0423 19:29:58.176633 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0423 19:29:58.176815 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0423 19:29:58.176896 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0423 19:29:58.178581 140471613556608 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0423 19:29:58.194007 140471613556608 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0423 19:29:58.194130 140471613556608 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0423 19:29:58.379257 140471613556608 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0423 19:29:58.379464 140471613556608 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0423 19:29:58.760442 140471613556608 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0423 19:29:58.760658 140471613556608 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I0423 19:29:59.147771 140471613556608 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I0423 19:29:59.147954 140471613556608 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I0423 19:29:59.678176 140471613556608 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I0423 19:29:59.678355 140471613556608 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I0423 19:30:00.231028 140471613556608 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I0423 19:30:00.231221 140471613556608 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I0423 19:30:00.935276 140471613556608 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I0423 19:30:00.935480 140471613556608 efficientnet_model.py:144] round_filter input=320 output=512\n",
            "I0423 19:30:01.176310 140471613556608 efficientnet_model.py:144] round_filter input=1280 output=2048\n",
            "I0423 19:30:01.205039 140471613556608 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0423 19:30:01.298707 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0423 19:30:01.298894 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0423 19:30:01.298978 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0423 19:30:01.300655 140471613556608 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I0423 19:30:01.316709 140471613556608 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I0423 19:30:01.316838 140471613556608 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0423 19:30:01.503619 140471613556608 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0423 19:30:01.503878 140471613556608 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0423 19:30:01.978711 140471613556608 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0423 19:30:01.978902 140471613556608 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I0423 19:30:02.454576 140471613556608 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I0423 19:30:02.454759 140471613556608 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I0423 19:30:03.088864 140471613556608 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I0423 19:30:03.089038 140471613556608 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I0423 19:30:03.957101 140471613556608 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I0423 19:30:03.957278 140471613556608 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I0423 19:30:04.813125 140471613556608 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I0423 19:30:04.813305 140471613556608 efficientnet_model.py:144] round_filter input=320 output=576\n",
            "I0423 19:30:05.043854 140471613556608 efficientnet_model.py:144] round_filter input=1280 output=2304\n",
            "I0423 19:30:05.071547 140471613556608 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0423 19:30:05.186679 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0423 19:30:05.186841 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0423 19:30:05.186922 140471613556608 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0423 19:30:05.188662 140471613556608 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I0423 19:30:05.204457 140471613556608 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I0423 19:30:05.204590 140471613556608 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0423 19:30:05.447946 140471613556608 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0423 19:30:05.448112 140471613556608 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I0423 19:30:06.274447 140471613556608 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I0423 19:30:06.274631 140471613556608 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I0423 19:30:07.097608 140471613556608 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I0423 19:30:07.097790 140471613556608 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I0423 19:30:08.131236 140471613556608 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I0423 19:30:08.131419 140471613556608 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I0423 19:30:08.901787 140471613556608 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I0423 19:30:08.902000 140471613556608 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I0423 19:30:09.904339 140471613556608 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I0423 19:30:09.904528 140471613556608 efficientnet_model.py:144] round_filter input=320 output=640\n",
            "I0423 19:30:10.479639 140471613556608 efficientnet_model.py:144] round_filter input=1280 output=2560\n",
            "I0423 19:30:10.507960 140471613556608 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.93s\n",
            "I0423 19:30:10.632315 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 22.93s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0423 19:30:10.639314 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0423 19:30:10.641040 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0423 19:30:10.641547 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0423 19:30:10.643080 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0423 19:30:10.644541 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0423 19:30:10.645018 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0423 19:30:10.646068 140471613556608 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 27.813s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "3OMm0UbdLg5t"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xl5AQceXLg5y",
        "outputId": "ebcd9ce9-8644-4994-cc85-911114f94dba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: protobuf 3.20.1\n",
            "Uninstalling protobuf-3.20.1:\n",
            "  Successfully uninstalled protobuf-3.20.1\n",
            "Found existing installation: matplotlib 3.2.0\n",
            "Uninstalling matplotlib-3.2.0:\n",
            "  Successfully uninstalled matplotlib-3.2.0\n",
            "Collecting protobuf\n",
            "  Using cached protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "Collecting matplotlib==3.2\n",
            "  Using cached matplotlib-3.2.0-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.2) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.2) (1.15.0)\n",
            "Installing collected packages: protobuf, matplotlib\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.2.0 protobuf-3.20.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip uninstall protobuf matplotlib -y\n",
        "!pip install protobuf matplotlib==3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YpC5VO0ILg50"
      },
      "outputs": [],
      "source": [
        "import object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "scrolled": true,
        "id": "_7T99de7Lg52",
        "outputId": "aae258fc-09e1-4567-b190-c07b8a80fedc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                       Version\n",
            "----------------------------- ---------------------\n",
            "absl-py                       1.0.0\n",
            "alabaster                     0.7.12\n",
            "albumentations                0.1.12\n",
            "altair                        4.2.0\n",
            "apache-beam                   2.38.0\n",
            "appdirs                       1.4.4\n",
            "argon2-cffi                   21.3.0\n",
            "argon2-cffi-bindings          21.2.0\n",
            "arviz                         0.12.0\n",
            "astor                         0.8.1\n",
            "astropy                       4.3.1\n",
            "astunparse                    1.6.3\n",
            "atari-py                      0.2.9\n",
            "atomicwrites                  1.4.0\n",
            "attrs                         21.4.0\n",
            "audioread                     2.1.9\n",
            "autograd                      1.4\n",
            "avro-python3                  1.10.2\n",
            "Babel                         2.9.1\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.6.3\n",
            "bleach                        5.0.0\n",
            "blis                          0.4.1\n",
            "bokeh                         2.3.3\n",
            "Bottleneck                    1.3.4\n",
            "branca                        0.4.2\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.10\n",
            "cached-property               1.5.2\n",
            "cachetools                    4.2.4\n",
            "catalogue                     1.0.0\n",
            "certifi                       2021.10.8\n",
            "cffi                          1.15.0\n",
            "cftime                        1.6.0\n",
            "chardet                       3.0.4\n",
            "charset-normalizer            2.0.12\n",
            "click                         7.1.2\n",
            "cloudpickle                   2.0.0\n",
            "cmake                         3.12.0\n",
            "cmdstanpy                     0.9.5\n",
            "colorama                      0.4.4\n",
            "colorcet                      3.0.0\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "contextlib2                   0.5.5\n",
            "convertdate                   2.4.0\n",
            "coverage                      3.7.1\n",
            "coveralls                     0.5\n",
            "crcmod                        1.7\n",
            "cufflinks                     0.17.3\n",
            "cupy-cuda111                  9.4.0\n",
            "cvxopt                        1.2.7\n",
            "cvxpy                         1.0.31\n",
            "cycler                        0.11.0\n",
            "cymem                         2.0.6\n",
            "Cython                        0.29.28\n",
            "daft                          0.0.4\n",
            "dask                          2.12.0\n",
            "datascience                   0.10.6\n",
            "debugpy                       1.0.0\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "descartes                     1.1.0\n",
            "dill                          0.3.1.1\n",
            "distributed                   1.25.3\n",
            "dlib                          19.18.0\n",
            "dm-tree                       0.1.7\n",
            "docopt                        0.6.2\n",
            "docutils                      0.17.1\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.306\n",
            "easydict                      1.9\n",
            "ecos                          2.0.10\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                2.2.5\n",
            "entrypoints                   0.4\n",
            "ephem                         4.1.3\n",
            "et-xmlfile                    1.1.0\n",
            "fa2                           0.3.5\n",
            "fastai                        1.0.61\n",
            "fastavro                      1.4.10\n",
            "fastdtw                       0.3.4\n",
            "fastjsonschema                2.15.3\n",
            "fastprogress                  1.0.2\n",
            "fastrlock                     0.8\n",
            "fbprophet                     0.7.1\n",
            "feather-format                0.4.1\n",
            "filelock                      3.6.0\n",
            "firebase-admin                4.4.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         1.1.4\n",
            "flatbuffers                   2.0\n",
            "folium                        0.8.3\n",
            "future                        0.16.0\n",
            "gast                          0.5.3\n",
            "GDAL                          2.2.2\n",
            "gdown                         4.4.0\n",
            "gensim                        3.6.0\n",
            "geographiclib                 1.52\n",
            "geopy                         1.17.0\n",
            "gin-config                    0.5.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               1.31.5\n",
            "google-api-python-client      1.12.11\n",
            "google-auth                   1.35.0\n",
            "google-auth-httplib2          0.0.4\n",
            "google-auth-oauthlib          0.4.6\n",
            "google-cloud-bigquery         1.21.0\n",
            "google-cloud-bigquery-storage 1.1.1\n",
            "google-cloud-core             1.0.3\n",
            "google-cloud-datastore        1.8.0\n",
            "google-cloud-firestore        1.7.0\n",
            "google-cloud-language         1.2.0\n",
            "google-cloud-storage          1.18.1\n",
            "google-cloud-translate        1.5.0\n",
            "google-colab                  1.0.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        0.4.1\n",
            "googleapis-common-protos      1.56.0\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.10.1\n",
            "greenlet                      1.1.2\n",
            "grpcio                        1.44.0\n",
            "gspread                       3.4.2\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.17.3\n",
            "h5py                          3.1.0\n",
            "hdfs                          2.7.0\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.2.3\n",
            "holidays                      0.10.5.2\n",
            "holoviews                     1.14.8\n",
            "html5lib                      1.0.1\n",
            "httpimport                    0.5.18\n",
            "httplib2                      0.17.4\n",
            "httplib2shim                  0.0.3\n",
            "humanize                      0.5.1\n",
            "hyperopt                      0.1.2\n",
            "ideep4py                      2.0.0.post3\n",
            "idna                          2.10\n",
            "imageio                       2.4.1\n",
            "imagesize                     1.3.0\n",
            "imbalanced-learn              0.8.1\n",
            "imblearn                      0.0\n",
            "imgaug                        0.2.9\n",
            "importlib-metadata            4.11.3\n",
            "importlib-resources           5.7.0\n",
            "imutils                       0.5.4\n",
            "inflect                       2.1.0\n",
            "iniconfig                     1.1.1\n",
            "intel-openmp                  2022.0.2\n",
            "intervaltree                  2.1.0\n",
            "ipykernel                     4.10.1\n",
            "ipython                       5.5.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    7.7.0\n",
            "itsdangerous                  1.1.0\n",
            "jax                           0.3.4\n",
            "jaxlib                        0.3.2+cuda11.cudnn805\n",
            "jedi                          0.18.1\n",
            "jieba                         0.42.1\n",
            "Jinja2                        2.11.3\n",
            "joblib                        1.1.0\n",
            "jpeg4py                       0.1.4\n",
            "jsonschema                    4.3.3\n",
            "jupyter                       1.0.0\n",
            "jupyter-client                5.3.5\n",
            "jupyter-console               5.2.0\n",
            "jupyter-core                  4.9.2\n",
            "jupyterlab-pygments           0.2.2\n",
            "jupyterlab-widgets            1.1.0\n",
            "kaggle                        1.5.12\n",
            "kapre                         0.3.7\n",
            "keras                         2.8.0\n",
            "Keras-Preprocessing           1.1.2\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.4.2\n",
            "korean-lunar-calendar         0.2.1\n",
            "libclang                      13.0.0\n",
            "librosa                       0.8.1\n",
            "lightgbm                      2.2.3\n",
            "llvmlite                      0.34.0\n",
            "lmdb                          0.99\n",
            "LunarCalendar                 0.0.9\n",
            "lvis                          0.5.3\n",
            "lxml                          4.2.6\n",
            "Markdown                      3.3.6\n",
            "MarkupSafe                    2.0.1\n",
            "matplotlib                    3.2.0\n",
            "matplotlib-inline             0.1.3\n",
            "matplotlib-venn               0.11.7\n",
            "missingno                     0.5.1\n",
            "mistune                       0.8.4\n",
            "mizani                        0.6.0\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                8.12.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.2.1\n",
            "msgpack                       1.0.3\n",
            "multiprocess                  0.70.12.2\n",
            "multitasking                  0.0.10\n",
            "murmurhash                    1.0.6\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbclient                      0.6.0\n",
            "nbconvert                     5.6.1\n",
            "nbformat                      5.3.0\n",
            "nest-asyncio                  1.5.5\n",
            "netCDF4                       1.5.8\n",
            "networkx                      2.6.3\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.2.5\n",
            "notebook                      5.3.1\n",
            "numba                         0.51.2\n",
            "numexpr                       2.8.1\n",
            "numpy                         1.21.6\n",
            "nvidia-ml-py3                 7.352.0\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.2.0\n",
            "object-detection              0.1\n",
            "okgrade                       0.4.3\n",
            "opencv-contrib-python         4.1.2.30\n",
            "opencv-python                 4.1.2.30\n",
            "opencv-python-headless        4.5.5.64\n",
            "openpyxl                      3.0.9\n",
            "opt-einsum                    3.3.0\n",
            "orjson                        3.6.8\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     21.3\n",
            "palettable                    3.3.0\n",
            "pandas                        1.3.5\n",
            "pandas-datareader             0.9.0\n",
            "pandas-gbq                    0.13.3\n",
            "pandas-profiling              1.4.1\n",
            "pandocfilters                 1.5.0\n",
            "panel                         0.12.1\n",
            "param                         1.12.1\n",
            "parso                         0.8.3\n",
            "pathlib                       1.0.1\n",
            "patsy                         0.5.2\n",
            "pep517                        0.12.0\n",
            "pexpect                       4.8.0\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        7.1.2\n",
            "pip                           21.1.3\n",
            "pip-tools                     6.2.0\n",
            "plac                          1.1.3\n",
            "plotly                        5.5.0\n",
            "plotnine                      0.6.0\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.6.0\n",
            "portalocker                   2.4.0\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.1\n",
            "preshed                       3.0.6\n",
            "prettytable                   3.2.0\n",
            "progressbar2                  3.38.0\n",
            "prometheus-client             0.14.1\n",
            "promise                       2.3\n",
            "prompt-toolkit                1.0.18\n",
            "proto-plus                    1.20.3\n",
            "protobuf                      3.20.1\n",
            "psutil                        5.4.8\n",
            "psycopg2                      2.7.6.1\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.11.0\n",
            "py-cpuinfo                    8.0.0\n",
            "pyarrow                       6.0.1\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.4\n",
            "pycparser                     2.21\n",
            "pyct                          0.4.8\n",
            "pydata-google-auth            1.4.0\n",
            "pydot                         1.3.0\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyemd                         0.5.1\n",
            "pyerfa                        2.0.0.1\n",
            "pyglet                        1.5.0\n",
            "Pygments                      2.6.1\n",
            "pygobject                     3.26.1\n",
            "pymc3                         3.11.4\n",
            "PyMeeus                       0.5.11\n",
            "pymongo                       3.12.3\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.6\n",
            "pyparsing                     3.0.8\n",
            "pyrsistent                    0.18.1\n",
            "pysndfile                     1.3.8\n",
            "PySocks                       1.7.1\n",
            "pystan                        2.19.1.1\n",
            "pytest                        3.6.4\n",
            "python-apt                    0.0.0\n",
            "python-chess                  0.23.11\n",
            "python-dateutil               2.8.2\n",
            "python-louvain                0.16\n",
            "python-slugify                6.1.1\n",
            "python-utils                  3.1.0\n",
            "pytz                          2022.1\n",
            "pyviz-comms                   2.2.0\n",
            "PyWavelets                    1.3.0\n",
            "PyYAML                        5.4.1\n",
            "pyzmq                         22.3.0\n",
            "qdldl                         0.1.5.post2\n",
            "qtconsole                     5.3.0\n",
            "QtPy                          2.0.1\n",
            "regex                         2019.12.20\n",
            "requests                      2.27.1\n",
            "requests-oauthlib             1.3.1\n",
            "resampy                       0.2.2\n",
            "rpy2                          3.4.5\n",
            "rsa                           4.8\n",
            "sacrebleu                     2.0.0\n",
            "scikit-image                  0.18.3\n",
            "scikit-learn                  1.0.2\n",
            "scipy                         1.4.1\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           3.2.0\n",
            "seaborn                       0.11.2\n",
            "semver                        2.13.0\n",
            "Send2Trash                    1.8.0\n",
            "sentencepiece                 0.1.96\n",
            "seqeval                       1.2.2\n",
            "setuptools                    57.4.0\n",
            "setuptools-git                1.2\n",
            "Shapely                       1.8.1.post1\n",
            "simplegeneric                 0.8.1\n",
            "six                           1.15.0\n",
            "sklearn                       0.0\n",
            "sklearn-pandas                1.8.0\n",
            "smart-open                    5.2.1\n",
            "snowballstemmer               2.2.0\n",
            "sortedcontainers              2.4.0\n",
            "SoundFile                     0.10.3.post1\n",
            "soupsieve                     2.3.2.post1\n",
            "spacy                         2.2.4\n",
            "Sphinx                        1.8.6\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "sphinxcontrib-websupport      1.2.4\n",
            "SQLAlchemy                    1.4.35\n",
            "sqlparse                      0.4.2\n",
            "srsly                         1.0.5\n",
            "statsmodels                   0.10.2\n",
            "sympy                         1.7.1\n",
            "tables                        3.7.0\n",
            "tabulate                      0.8.9\n",
            "tblib                         1.7.0\n",
            "tenacity                      8.0.1\n",
            "tensorboard                   2.8.0\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.1\n",
            "tensorflow                    2.8.0\n",
            "tensorflow-addons             0.16.1\n",
            "tensorflow-datasets           4.0.1\n",
            "tensorflow-estimator          2.8.0\n",
            "tensorflow-gcs-config         2.8.0\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-io                 0.25.0\n",
            "tensorflow-io-gcs-filesystem  0.25.0\n",
            "tensorflow-metadata           1.7.0\n",
            "tensorflow-model-optimization 0.7.2\n",
            "tensorflow-probability        0.16.0\n",
            "tensorflow-text               2.8.2\n",
            "termcolor                     1.1.0\n",
            "terminado                     0.13.3\n",
            "testpath                      0.6.0\n",
            "text-unidecode                1.3\n",
            "textblob                      0.15.3\n",
            "tf-estimator-nightly          2.8.0.dev2021122109\n",
            "tf-models-official            2.8.0\n",
            "tf-slim                       1.1.0\n",
            "Theano-PyMC                   1.1.2\n",
            "thinc                         7.4.0\n",
            "threadpoolctl                 3.1.0\n",
            "tifffile                      2021.11.2\n",
            "tinycss2                      1.1.1\n",
            "tomli                         2.0.1\n",
            "toolz                         0.11.2\n",
            "torch                         1.10.0+cu111\n",
            "torchaudio                    0.10.0+cu111\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.11.0\n",
            "torchvision                   0.11.1+cu111\n",
            "tornado                       5.1.1\n",
            "tqdm                          4.64.0\n",
            "traitlets                     5.1.1\n",
            "tweepy                        3.10.0\n",
            "typeguard                     2.7.1\n",
            "typing-extensions             4.1.1\n",
            "tzlocal                       1.5.1\n",
            "uritemplate                   3.0.1\n",
            "urllib3                       1.24.3\n",
            "vega-datasets                 0.9.0\n",
            "wasabi                        0.9.1\n",
            "wcwidth                       0.2.5\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      1.0.1\n",
            "wheel                         0.37.1\n",
            "widgetsnbextension            3.6.0\n",
            "wordcloud                     1.5.0\n",
            "wrapt                         1.14.0\n",
            "xarray                        0.18.2\n",
            "xgboost                       0.90\n",
            "xkit                          0.0.0\n",
            "xlrd                          1.1.0\n",
            "xlwt                          1.3.0\n",
            "yellowbrick                   1.4\n",
            "zict                          2.1.0\n",
            "zipp                          3.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csofht2npfDE",
        "outputId": "0ef6d696-9173-4a27-beda-76a8171f3b87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-23 19:30:11--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.107.128, 2607:f8b0:400e:c08::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.107.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-04-23 19:30:11 (134 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
            "\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KJTnkfpfDC"
      },
      "source": [
        "# 2. Create Label Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "p1BVDWo7pfDC"
      },
      "outputs": [],
      "source": [
        "labels = [{'name':'Bhalo', 'id':1}, {'name':'Kharap', 'id':2}, {'name':'Dhonnobad', 'id':3}, {'name':'Pani', 'id':4},{'name':'Bondhu', 'id':5}]\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C88zyVELpfDC"
      },
      "source": [
        "# 3. Create TF records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvf5WccwrFGq",
        "outputId": "1ff26675-8cde-49a7-d49e-fa95cf2e4e26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow/workspace/images/train/\n",
            "Tensorflow/workspace/images/train/bhalo.6d05c5b0-c310-11ec-baa5-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bhalo.6d05c5b0-c310-11ec-baa5-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bhalo.70a610da-c310-11ec-aefd-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bhalo.70a610da-c310-11ec-aefd-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bhalo.71dbb957-c310-11ec-9052-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bhalo.71dbb957-c310-11ec-9052-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bhalo.730f521e-c310-11ec-919b-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bhalo.730f521e-c310-11ec-919b-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bhalo.74445c7e-c310-11ec-a334-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bhalo.74445c7e-c310-11ec-a334-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bhalo.b994ef3e-c30f-11ec-97df-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bhalo.b994ef3e-c30f-11ec-97df-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bhalo.bacbc115-c30f-11ec-a084-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bhalo.bacbc115-c30f-11ec-a084-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bhalo.bc030c41-c30f-11ec-aea9-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bhalo.bc030c41-c30f-11ec-aea9-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.00bf662e-c310-11ec-8a71-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.00bf662e-c310-11ec-8a71-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.01f423e4-c310-11ec-aed5-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.01f423e4-c310-11ec-aed5-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.41c49223-c30f-11ec-aef7-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.41c49223-c30f-11ec-aef7-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.46a17bfd-c30f-11ec-a45a-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.46a17bfd-c30f-11ec-a45a-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.47d71ab1-c30f-11ec-b00a-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.47d71ab1-c30f-11ec-b00a-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.490bdab5-c30f-11ec-942d-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.490bdab5-c30f-11ec-942d-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.4a3fba60-c30f-11ec-aea1-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.4a3fba60-c30f-11ec-aea1-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.4b75cd24-c30f-11ec-9a24-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.4b75cd24-c30f-11ec-9a24-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.ba2da6a9-c30e-11ec-b25f-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.ba2da6a9-c30e-11ec-b25f-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.bb621d01-c30e-11ec-ba32-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.bb621d01-c30e-11ec-ba32-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.bdcd76ca-c30e-11ec-a758-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.bdcd76ca-c30e-11ec-a758-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.bf05264a-c30e-11ec-9fdf-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.bf05264a-c30e-11ec-9fdf-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.c03866fb-c30e-11ec-92ea-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.c03866fb-c30e-11ec-92ea-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.c16f2043-c30e-11ec-844d-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.c16f2043-c30e-11ec-844d-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.f83dde37-c30f-11ec-aa8c-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.f83dde37-c30f-11ec-aa8c-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.faae63c3-c30f-11ec-b8e7-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.faae63c3-c30f-11ec-b8e7-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.fbe536bd-c30f-11ec-95eb-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.fbe536bd-c30f-11ec-95eb-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/bondhu.ff89dbb1-c30f-11ec-a1e8-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/bondhu.ff89dbb1-c30f-11ec-a1e8-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/dhonnobad.d67ff987-c30f-11ec-992a-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/dhonnobad.d67ff987-c30f-11ec-992a-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/dhonnobad.d718ff87-c30e-11ec-839b-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/dhonnobad.d718ff87-c30e-11ec-839b-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/dhonnobad.d7b4edb6-c30f-11ec-ab98-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/dhonnobad.d7b4edb6-c30f-11ec-ab98-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/dhonnobad.d85075c8-c30e-11ec-bbe9-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/dhonnobad.d85075c8-c30e-11ec-bbe9-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/dhonnobad.d8ea64dd-c30f-11ec-9503-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/dhonnobad.d8ea64dd-c30f-11ec-9503-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/dhonnobad.d9865301-c30e-11ec-89d2-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/dhonnobad.d9865301-c30e-11ec-89d2-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/dhonnobad.da1fdf50-c30f-11ec-b906-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/dhonnobad.da1fdf50-c30f-11ec-b906-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/dhonnobad.dabf2d55-c30e-11ec-ba73-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/dhonnobad.dabf2d55-c30e-11ec-ba73-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/dhonnobad.db538789-c30f-11ec-bf83-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/dhonnobad.db538789-c30f-11ec-bf83-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/dhonnobad.dc86e9e6-c30f-11ec-82dc-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/dhonnobad.dc86e9e6-c30f-11ec-82dc-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/dhonnobad.dd2d7317-c30e-11ec-b9c6-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/dhonnobad.dd2d7317-c30e-11ec-b9c6-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/dhonnobad.ddba06df-c30f-11ec-8713-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/dhonnobad.ddba06df-c30f-11ec-8713-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/dhonnobad.de6680f3-c30e-11ec-9979-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/dhonnobad.de6680f3-c30e-11ec-9979-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/dhonnobad.deee8169-c30f-11ec-9e8f-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/dhonnobad.deee8169-c30f-11ec-9e8f-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/dhonnobad.df9bab88-c30e-11ec-bb20-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/dhonnobad.df9bab88-c30e-11ec-bb20-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/dhonnobad.e0d33cf8-c30e-11ec-8a37-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/dhonnobad.e0d33cf8-c30e-11ec-8a37-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/kharap.5daa5dc3-c310-11ec-b345-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/kharap.5daa5dc3-c310-11ec-b345-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/kharap.5edfbef1-c310-11ec-b253-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/kharap.5edfbef1-c310-11ec-b253-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/kharap.601436ac-c310-11ec-9f6b-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/kharap.601436ac-c310-11ec-9f6b-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/kharap.614be9f4-c310-11ec-83b2-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/kharap.614be9f4-c310-11ec-83b2-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/kharap.6280ff5e-c310-11ec-a06d-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/kharap.6280ff5e-c310-11ec-a06d-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/kharap.63b889d7-c310-11ec-98c0-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/kharap.63b889d7-c310-11ec-98c0-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/kharap.64ed640d-c310-11ec-82dc-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/kharap.64ed640d-c310-11ec-82dc-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/kharap.79a251da-c310-11ec-8a52-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/kharap.79a251da-c310-11ec-8a52-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/kharap.7ad89d6b-c310-11ec-b951-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/kharap.7ad89d6b-c310-11ec-b951-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/kharap.7c0f535a-c310-11ec-8dc0-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/kharap.7c0f535a-c310-11ec-8dc0-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/kharap.7d43b4ef-c310-11ec-b2d9-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/kharap.7d43b4ef-c310-11ec-b2d9-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/kharap.7e787e3b-c310-11ec-bcbb-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/kharap.7e787e3b-c310-11ec-bcbb-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/kharap.7face81e-c310-11ec-b696-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/kharap.7face81e-c310-11ec-b696-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/kharap.80e1d849-c310-11ec-8566-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/kharap.80e1d849-c310-11ec-8566-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/kharap.cc47188f-c30f-11ec-927e-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/kharap.cc47188f-c30f-11ec-927e-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/kharap.cd7c172e-c30f-11ec-94ab-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/kharap.cd7c172e-c30f-11ec-94ab-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/kharap.ceb1b19f-c30f-11ec-8036-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/kharap.ceb1b19f-c30f-11ec-8036-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/pani.e6b03ae9-c30f-11ec-97b7-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/pani.e6b03ae9-c30f-11ec-97b7-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/pani.e7e7603e-c30f-11ec-8bc1-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/pani.e7e7603e-c30f-11ec-8bc1-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/pani.e8a29c9b-c30e-11ec-9de6-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/pani.e8a29c9b-c30e-11ec-9de6-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/pani.e91d042d-c30f-11ec-9a69-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/pani.e91d042d-c30f-11ec-9a69-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/pani.e9d86bcb-c30e-11ec-8318-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/pani.e9d86bcb-c30e-11ec-8318-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/pani.eb0ea424-c30e-11ec-9982-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/pani.eb0ea424-c30e-11ec-9982-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/pani.eb8607e1-c30f-11ec-9e80-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/pani.eb8607e1-c30f-11ec-9e80-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/pani.ec43d921-c30e-11ec-9039-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/pani.ec43d921-c30e-11ec-9039-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/pani.ed771dfb-c30e-11ec-8647-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/pani.ed771dfb-c30e-11ec-8647-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/pani.edf4e7b2-c30f-11ec-af12-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/pani.edf4e7b2-c30f-11ec-af12-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/pani.ef2b2016-c30f-11ec-a200-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/pani.ef2b2016-c30f-11ec-a200-e702d947c991.xml\n",
            "Tensorflow/workspace/images/train/pani.f11af773-c30e-11ec-aae3-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/train/pani.f11af773-c30e-11ec-aae3-e702d947c991.xml\n",
            "Tensorflow/workspace/images/test/\n",
            "Tensorflow/workspace/images/test/bhalo.bd3a7ae3-c30f-11ec-9125-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/test/bhalo.bd3a7ae3-c30f-11ec-9125-e702d947c991.xml\n",
            "Tensorflow/workspace/images/test/bhalo.be6e1d8f-c30f-11ec-b3bb-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/test/bhalo.be6e1d8f-c30f-11ec-b3bb-e702d947c991.xml\n",
            "Tensorflow/workspace/images/test/bondhu.fd1baead-c30f-11ec-9eec-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/test/bondhu.fd1baead-c30f-11ec-9eec-e702d947c991.xml\n",
            "Tensorflow/workspace/images/test/bondhu.fe52de0e-c30f-11ec-9ad5-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/test/bondhu.fe52de0e-c30f-11ec-9ad5-e702d947c991.xml\n",
            "Tensorflow/workspace/images/test/dhonnobad.e1568420-c30f-11ec-a18f-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/test/dhonnobad.e1568420-c30f-11ec-a18f-e702d947c991.xml\n",
            "Tensorflow/workspace/images/test/dhonnobad.e2088dba-c30e-11ec-b045-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/test/dhonnobad.e2088dba-c30e-11ec-b045-e702d947c991.xml\n",
            "Tensorflow/workspace/images/test/kharap.cfe67fcd-c30f-11ec-b717-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/test/kharap.cfe67fcd-c30f-11ec-b717-e702d947c991.xml\n",
            "Tensorflow/workspace/images/test/kharap.d11d9e45-c30f-11ec-b56f-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/test/kharap.d11d9e45-c30f-11ec-b56f-e702d947c991.xml\n",
            "Tensorflow/workspace/images/test/pani.f1996fc8-c30f-11ec-bbd6-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/test/pani.f1996fc8-c30f-11ec-bbd6-e702d947c991.xml\n",
            "Tensorflow/workspace/images/test/pani.f24f4942-c30e-11ec-819d-e702d947c991.jpg\n",
            "Tensorflow/workspace/images/test/pani.f24f4942-c30e-11ec-819d-e702d947c991.xml\n"
          ]
        }
      ],
      "source": [
        "# OPTIONAL IF RUNNING ON COLAB\n",
        "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
        "if os.path.exists(ARCHIVE_FILES):\n",
        "  !tar -zxvf {ARCHIVE_FILES}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KWpb_BVUpfDD"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPFToGZqpfDD",
        "outputId": "36701152-c5b0-479f-be29-b5a64600f57c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ],
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "o6dvGgf4Lg6t"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "yWMPKxjiLg6u"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT4QU7pLpfDE"
      },
      "source": [
        "# 4. Copy Model Config to Training Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cOjuTFbwpfDF"
      },
      "outputs": [],
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8gpNslpfDF"
      },
      "source": [
        "# 5. Update Config For Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Z9hRrO_ppfDF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "c2A0mn4ipfDF"
      },
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQA13-afpfDF",
        "outputId": "2a8614df-3099-4b30-fd88-09fb35a36931"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false,\n",
              " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " },\n",
              " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ],\n",
              " 'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 320\n",
              "       width: 320\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9vK5lotDpfDF"
      },
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rP43Ph0JpfDG"
      },
      "outputs": [],
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "oJvfgwWqpfDG"
      },
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr3ON7xMpfDG"
      },
      "source": [
        "# 6. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "B-Y2UQmQpfDG"
      },
      "outputs": [],
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jMP2XDfQpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4OXXi-ApfDH",
        "outputId": "fee6547a-3c59-4bac-e092-b7610c750400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python-headless==4.5.2.52"
      ],
      "metadata": {
        "id": "4tD9te2PQw-y",
        "outputId": "4a869484-119e-42cb-8f86-5fd4099af8da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.2.52) (1.21.6)\n",
            "Installing collected packages: opencv-python-headless\n",
            "Successfully installed opencv-python-headless-4.5.2.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ZsJR-qpfDH",
        "outputId": "f6fe16f0-616a-4cd6-8706-ab1b6d3970a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-23 18:13:34.032252: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0423 18:13:34.037903 139685929953152 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
            "I0423 18:13:34.041711 139685929953152 config_util.py:552] Maybe overwriting train_steps: 2000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0423 18:13:34.041862 139685929953152 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0423 18:13:34.184263 139685929953152 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0423 18:13:34.188707 139685929953152 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0423 18:13:34.188893 139685929953152 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0423 18:13:34.188980 139685929953152 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0423 18:13:34.189069 139685929953152 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0423 18:13:34.191578 139685929953152 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0423 18:13:34.211503 139685929953152 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0423 18:13:41.407361 139685929953152 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0423 18:13:44.560790 139685929953152 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0423 18:13:46.276660 139685929953152 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0423 18:14:20.174978 139685929953152 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0423 18:14:20.176188 139685929953152 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0423 18:14:20.178251 139685929953152 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0423 18:14:20.179144 139685929953152 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0423 18:14:20.181219 139685929953152 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0423 18:14:20.182154 139685929953152 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0423 18:14:20.184201 139685929953152 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0423 18:14:20.185118 139685929953152 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0423 18:14:20.187136 139685929953152 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0423 18:14:20.188034 139685929953152 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0423 18:14:20.853118 139680754370304 deprecation.py:547] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 0.413s\n",
            "I0423 18:15:01.982459 139685929953152 model_lib_v2.py:707] Step 100 per-step time 0.413s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.32734513,\n",
            " 'Loss/localization_loss': 0.34573472,\n",
            " 'Loss/regularization_loss': 0.15444134,\n",
            " 'Loss/total_loss': 0.8275212,\n",
            " 'learning_rate': 0.0319994}\n",
            "I0423 18:15:01.982814 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.32734513,\n",
            " 'Loss/localization_loss': 0.34573472,\n",
            " 'Loss/regularization_loss': 0.15444134,\n",
            " 'Loss/total_loss': 0.8275212,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 0.093s\n",
            "I0423 18:15:11.110018 139685929953152 model_lib_v2.py:707] Step 200 per-step time 0.093s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3044345,\n",
            " 'Loss/localization_loss': 0.21911879,\n",
            " 'Loss/regularization_loss': 0.15453851,\n",
            " 'Loss/total_loss': 0.6780918,\n",
            " 'learning_rate': 0.0373328}\n",
            "I0423 18:15:11.110353 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.3044345,\n",
            " 'Loss/localization_loss': 0.21911879,\n",
            " 'Loss/regularization_loss': 0.15453851,\n",
            " 'Loss/total_loss': 0.6780918,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 0.092s\n",
            "I0423 18:15:20.284529 139685929953152 model_lib_v2.py:707] Step 300 per-step time 0.092s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15810952,\n",
            " 'Loss/localization_loss': 0.11325848,\n",
            " 'Loss/regularization_loss': 0.15436491,\n",
            " 'Loss/total_loss': 0.4257329,\n",
            " 'learning_rate': 0.0426662}\n",
            "I0423 18:15:20.285109 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.15810952,\n",
            " 'Loss/localization_loss': 0.11325848,\n",
            " 'Loss/regularization_loss': 0.15436491,\n",
            " 'Loss/total_loss': 0.4257329,\n",
            " 'learning_rate': 0.0426662}\n",
            "INFO:tensorflow:Step 400 per-step time 0.092s\n",
            "I0423 18:15:29.486516 139685929953152 model_lib_v2.py:707] Step 400 per-step time 0.092s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.104058996,\n",
            " 'Loss/localization_loss': 0.09504266,\n",
            " 'Loss/regularization_loss': 0.15404576,\n",
            " 'Loss/total_loss': 0.35314742,\n",
            " 'learning_rate': 0.047999598}\n",
            "I0423 18:15:29.486863 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.104058996,\n",
            " 'Loss/localization_loss': 0.09504266,\n",
            " 'Loss/regularization_loss': 0.15404576,\n",
            " 'Loss/total_loss': 0.35314742,\n",
            " 'learning_rate': 0.047999598}\n",
            "INFO:tensorflow:Step 500 per-step time 0.092s\n",
            "I0423 18:15:38.670537 139685929953152 model_lib_v2.py:707] Step 500 per-step time 0.092s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16510355,\n",
            " 'Loss/localization_loss': 0.11736558,\n",
            " 'Loss/regularization_loss': 0.15375166,\n",
            " 'Loss/total_loss': 0.43622077,\n",
            " 'learning_rate': 0.053333}\n",
            "I0423 18:15:38.670879 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.16510355,\n",
            " 'Loss/localization_loss': 0.11736558,\n",
            " 'Loss/regularization_loss': 0.15375166,\n",
            " 'Loss/total_loss': 0.43622077,\n",
            " 'learning_rate': 0.053333}\n",
            "INFO:tensorflow:Step 600 per-step time 0.091s\n",
            "I0423 18:15:47.765403 139685929953152 model_lib_v2.py:707] Step 600 per-step time 0.091s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.27458036,\n",
            " 'Loss/localization_loss': 0.11428278,\n",
            " 'Loss/regularization_loss': 0.15335429,\n",
            " 'Loss/total_loss': 0.54221743,\n",
            " 'learning_rate': 0.0586664}\n",
            "I0423 18:15:47.765754 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.27458036,\n",
            " 'Loss/localization_loss': 0.11428278,\n",
            " 'Loss/regularization_loss': 0.15335429,\n",
            " 'Loss/total_loss': 0.54221743,\n",
            " 'learning_rate': 0.0586664}\n",
            "INFO:tensorflow:Step 700 per-step time 0.091s\n",
            "I0423 18:15:56.902838 139685929953152 model_lib_v2.py:707] Step 700 per-step time 0.091s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16263168,\n",
            " 'Loss/localization_loss': 0.15161523,\n",
            " 'Loss/regularization_loss': 0.1529109,\n",
            " 'Loss/total_loss': 0.46715778,\n",
            " 'learning_rate': 0.0639998}\n",
            "I0423 18:15:56.904139 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.16263168,\n",
            " 'Loss/localization_loss': 0.15161523,\n",
            " 'Loss/regularization_loss': 0.1529109,\n",
            " 'Loss/total_loss': 0.46715778,\n",
            " 'learning_rate': 0.0639998}\n",
            "INFO:tensorflow:Step 800 per-step time 0.091s\n",
            "I0423 18:16:05.962158 139685929953152 model_lib_v2.py:707] Step 800 per-step time 0.091s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07589255,\n",
            " 'Loss/localization_loss': 0.07449892,\n",
            " 'Loss/regularization_loss': 0.15237075,\n",
            " 'Loss/total_loss': 0.3027622,\n",
            " 'learning_rate': 0.069333196}\n",
            "I0423 18:16:05.962469 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.07589255,\n",
            " 'Loss/localization_loss': 0.07449892,\n",
            " 'Loss/regularization_loss': 0.15237075,\n",
            " 'Loss/total_loss': 0.3027622,\n",
            " 'learning_rate': 0.069333196}\n",
            "INFO:tensorflow:Step 900 per-step time 0.091s\n",
            "I0423 18:16:15.042145 139685929953152 model_lib_v2.py:707] Step 900 per-step time 0.091s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1314824,\n",
            " 'Loss/localization_loss': 0.08825003,\n",
            " 'Loss/regularization_loss': 0.15186685,\n",
            " 'Loss/total_loss': 0.3715993,\n",
            " 'learning_rate': 0.074666604}\n",
            "I0423 18:16:15.042500 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.1314824,\n",
            " 'Loss/localization_loss': 0.08825003,\n",
            " 'Loss/regularization_loss': 0.15186685,\n",
            " 'Loss/total_loss': 0.3715993,\n",
            " 'learning_rate': 0.074666604}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.091s\n",
            "I0423 18:16:24.177335 139685929953152 model_lib_v2.py:707] Step 1000 per-step time 0.091s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14824256,\n",
            " 'Loss/localization_loss': 0.07707849,\n",
            " 'Loss/regularization_loss': 0.15130465,\n",
            " 'Loss/total_loss': 0.37662572,\n",
            " 'learning_rate': 0.08}\n",
            "I0423 18:16:24.177740 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.14824256,\n",
            " 'Loss/localization_loss': 0.07707849,\n",
            " 'Loss/regularization_loss': 0.15130465,\n",
            " 'Loss/total_loss': 0.37662572,\n",
            " 'learning_rate': 0.08}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.097s\n",
            "I0423 18:16:33.884816 139685929953152 model_lib_v2.py:707] Step 1100 per-step time 0.097s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15629742,\n",
            " 'Loss/localization_loss': 0.09099644,\n",
            " 'Loss/regularization_loss': 0.1506735,\n",
            " 'Loss/total_loss': 0.39796734,\n",
            " 'learning_rate': 0.07999918}\n",
            "I0423 18:16:33.885487 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.15629742,\n",
            " 'Loss/localization_loss': 0.09099644,\n",
            " 'Loss/regularization_loss': 0.1506735,\n",
            " 'Loss/total_loss': 0.39796734,\n",
            " 'learning_rate': 0.07999918}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.091s\n",
            "I0423 18:16:43.030899 139685929953152 model_lib_v2.py:707] Step 1200 per-step time 0.091s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1372753,\n",
            " 'Loss/localization_loss': 0.053208593,\n",
            " 'Loss/regularization_loss': 0.15000671,\n",
            " 'Loss/total_loss': 0.34049058,\n",
            " 'learning_rate': 0.079996705}\n",
            "I0423 18:16:43.031227 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.1372753,\n",
            " 'Loss/localization_loss': 0.053208593,\n",
            " 'Loss/regularization_loss': 0.15000671,\n",
            " 'Loss/total_loss': 0.34049058,\n",
            " 'learning_rate': 0.079996705}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.092s\n",
            "I0423 18:16:52.217517 139685929953152 model_lib_v2.py:707] Step 1300 per-step time 0.092s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1191848,\n",
            " 'Loss/localization_loss': 0.053144515,\n",
            " 'Loss/regularization_loss': 0.14933625,\n",
            " 'Loss/total_loss': 0.32166556,\n",
            " 'learning_rate': 0.0799926}\n",
            "I0423 18:16:52.217827 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.1191848,\n",
            " 'Loss/localization_loss': 0.053144515,\n",
            " 'Loss/regularization_loss': 0.14933625,\n",
            " 'Loss/total_loss': 0.32166556,\n",
            " 'learning_rate': 0.0799926}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.094s\n",
            "I0423 18:17:01.660045 139685929953152 model_lib_v2.py:707] Step 1400 per-step time 0.094s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1425296,\n",
            " 'Loss/localization_loss': 0.07640868,\n",
            " 'Loss/regularization_loss': 0.14868444,\n",
            " 'Loss/total_loss': 0.36762273,\n",
            " 'learning_rate': 0.07998685}\n",
            "I0423 18:17:01.660338 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.1425296,\n",
            " 'Loss/localization_loss': 0.07640868,\n",
            " 'Loss/regularization_loss': 0.14868444,\n",
            " 'Loss/total_loss': 0.36762273,\n",
            " 'learning_rate': 0.07998685}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.091s\n",
            "I0423 18:17:10.764779 139685929953152 model_lib_v2.py:707] Step 1500 per-step time 0.091s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16039445,\n",
            " 'Loss/localization_loss': 0.08423067,\n",
            " 'Loss/regularization_loss': 0.14805342,\n",
            " 'Loss/total_loss': 0.39267856,\n",
            " 'learning_rate': 0.07997945}\n",
            "I0423 18:17:10.765103 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.16039445,\n",
            " 'Loss/localization_loss': 0.08423067,\n",
            " 'Loss/regularization_loss': 0.14805342,\n",
            " 'Loss/total_loss': 0.39267856,\n",
            " 'learning_rate': 0.07997945}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.092s\n",
            "I0423 18:17:20.012907 139685929953152 model_lib_v2.py:707] Step 1600 per-step time 0.092s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.085286476,\n",
            " 'Loss/localization_loss': 0.083334155,\n",
            " 'Loss/regularization_loss': 0.14740618,\n",
            " 'Loss/total_loss': 0.3160268,\n",
            " 'learning_rate': 0.079970405}\n",
            "I0423 18:17:20.013225 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.085286476,\n",
            " 'Loss/localization_loss': 0.083334155,\n",
            " 'Loss/regularization_loss': 0.14740618,\n",
            " 'Loss/total_loss': 0.3160268,\n",
            " 'learning_rate': 0.079970405}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.093s\n",
            "I0423 18:17:29.329020 139685929953152 model_lib_v2.py:707] Step 1700 per-step time 0.093s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.076773405,\n",
            " 'Loss/localization_loss': 0.03990203,\n",
            " 'Loss/regularization_loss': 0.14671342,\n",
            " 'Loss/total_loss': 0.26338887,\n",
            " 'learning_rate': 0.07995972}\n",
            "I0423 18:17:29.329365 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.076773405,\n",
            " 'Loss/localization_loss': 0.03990203,\n",
            " 'Loss/regularization_loss': 0.14671342,\n",
            " 'Loss/total_loss': 0.26338887,\n",
            " 'learning_rate': 0.07995972}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.091s\n",
            "I0423 18:17:38.463073 139685929953152 model_lib_v2.py:707] Step 1800 per-step time 0.091s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.087746985,\n",
            " 'Loss/localization_loss': 0.050734274,\n",
            " 'Loss/regularization_loss': 0.14602512,\n",
            " 'Loss/total_loss': 0.28450638,\n",
            " 'learning_rate': 0.0799474}\n",
            "I0423 18:17:38.463397 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.087746985,\n",
            " 'Loss/localization_loss': 0.050734274,\n",
            " 'Loss/regularization_loss': 0.14602512,\n",
            " 'Loss/total_loss': 0.28450638,\n",
            " 'learning_rate': 0.0799474}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.091s\n",
            "I0423 18:17:47.608403 139685929953152 model_lib_v2.py:707] Step 1900 per-step time 0.091s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0693801,\n",
            " 'Loss/localization_loss': 0.046136014,\n",
            " 'Loss/regularization_loss': 0.14538915,\n",
            " 'Loss/total_loss': 0.26090527,\n",
            " 'learning_rate': 0.07993342}\n",
            "I0423 18:17:47.608716 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.0693801,\n",
            " 'Loss/localization_loss': 0.046136014,\n",
            " 'Loss/regularization_loss': 0.14538915,\n",
            " 'Loss/total_loss': 0.26090527,\n",
            " 'learning_rate': 0.07993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.092s\n",
            "I0423 18:17:56.801257 139685929953152 model_lib_v2.py:707] Step 2000 per-step time 0.092s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08108284,\n",
            " 'Loss/localization_loss': 0.0356203,\n",
            " 'Loss/regularization_loss': 0.14472945,\n",
            " 'Loss/total_loss': 0.2614326,\n",
            " 'learning_rate': 0.07991781}\n",
            "I0423 18:17:56.801604 139685929953152 model_lib_v2.py:708] {'Loss/classification_loss': 0.08108284,\n",
            " 'Loss/localization_loss': 0.0356203,\n",
            " 'Loss/regularization_loss': 0.14472945,\n",
            " 'Loss/total_loss': 0.2614326,\n",
            " 'learning_rate': 0.07991781}\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_YRZu7npfDH"
      },
      "source": [
        "# 7. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "80L7-fdPpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "lYsgEPx9pfDH",
        "outputId": "b20f6e9e-1b82-4576-fd6e-f5d1c40af2b8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-abbd8280e00e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'command' is not defined"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqTV2jGBpfDH"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orvRk02UpfDI"
      },
      "source": [
        "# 8. Load Train Model From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "8TYk4_oIpfDI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tDnQg-cYpfDI"
      },
      "outputs": [],
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EmsmbBZpfDI"
      },
      "source": [
        "# 9. Detect from an Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Y_MKiuZ4pfDI"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "cBDbIhNapfDI"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Lx3crOhOzITB"
      },
      "outputs": [],
      "source": [
        "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'bhalo.be6e1d8f-c30f-11ec-b3bb-e702d947c991.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "Tpzn1SMry1yK",
        "outputId": "faeeb35c-cfef-43b5-ae88-ae165b1920d0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-999d48cacdb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_detections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_detections'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    954\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m         raise ValueError(\"Creating variables on a non-first call to a function\"\n\u001b[0m\u001b[1;32m    957\u001b[0m                          \" decorated with tf.function.\")\n\u001b[1;32m    958\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."
          ]
        }
      ],
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=5,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsNAaYAo0WVL"
      },
      "source": [
        "# 10. Real Time Detections from your Webcam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa-Y1v4XLg8x"
      },
      "outputs": [],
      "source": [
        "!pip uninstall opencv-python-headless -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_grs6OGpfDJ"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "while cap.isOpened(): \n",
        "    ret, frame = cap.read()\n",
        "    image_np = np.array(frame)\n",
        "    \n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "    \n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np_with_detections,\n",
        "                detections['detection_boxes'],\n",
        "                detections['detection_classes']+label_id_offset,\n",
        "                detections['detection_scores'],\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                max_boxes_to_draw=5,\n",
        "                min_score_thresh=.8,\n",
        "                agnostic_mode=False)\n",
        "\n",
        "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
        "    \n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzlM4jt0pfDJ"
      },
      "source": [
        "# 10. Freezing the Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4olHB2npfDJ"
      },
      "outputs": [],
      "source": [
        "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AjO93QDpfDJ"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6Lsp3tCpfDJ"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Sw1ULgHpfDJ"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTPmdqaXpfDK"
      },
      "source": [
        "# 11. Conversion to TFJS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ6UzY_fpfDK",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oxbVynHpfDK"
      },
      "outputs": [],
      "source": [
        "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB2AGNmJpfDK"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7rfT4-hpfDK"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8_hm-itpfDK"
      },
      "outputs": [],
      "source": [
        "# Test Code: https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtUw73FHpfDK"
      },
      "source": [
        "# 12. Conversion to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XviMtewLpfDK"
      },
      "outputs": [],
      "source": [
        "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us86cjC4pfDL"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1r5YO3rpfDL"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-xWpHN8pfDL"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJfYMbN6pfDL"
      },
      "outputs": [],
      "source": [
        "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
        "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY4lnLW5Lg-Z"
      },
      "outputs": [],
      "source": [
        "command = \"tflite_convert \\\n",
        "--saved_model_dir={} \\\n",
        "--output_file={} \\\n",
        "--input_shapes=1,300,300,3 \\\n",
        "--input_arrays=normalized_input_image_tensor \\\n",
        "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
        "--inference_type=FLOAT \\\n",
        "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8GwUeoFpfDL"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbd7gqHMpfDL"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NQqZRdA21Uc"
      },
      "source": [
        "# 13. Zip and Export Models "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTVTGCQp2ZJJ"
      },
      "outputs": [],
      "source": [
        "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whShhB0x3PYJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "3. Training and Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "bangla",
      "language": "python",
      "name": "bangla"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}